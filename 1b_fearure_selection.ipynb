{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "import seaborn as sns\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.linear_model import Ridge\n",
    "import math\n",
    "from itertools import zip_longest\n",
    "import random\n",
    "from feature_selection import get_elastic_importances, get_lasso_importances, get_anova_importances\n",
    "from collections import defaultdict\n",
    "from sklearn.feature_selection import f_classif\n",
    "#to get rid of the warning\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: 1377          Bream\n",
      "209           Smelt\n",
      "1310          Bream\n",
      "1461           Pike\n",
      "59             Pike\n",
      "           ...     \n",
      "1131          Perch\n",
      "1295          Perch\n",
      "861     SilverBream\n",
      "1460          Smelt\n",
      "1127    SilverBream\n",
      "Name: Species, Length: 1306, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#data\n",
    "data = pd.read_csv('Fish3.txt', delimiter=' ')\n",
    "\n",
    "X = data.drop('Species', axis=1)\n",
    "target = data['Species']\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "X_train, X_test, target_train, target_test = train_test_split(X, target, test_size=0.3, random_state=seed)\n",
    "print(\"X_train shape:\" , target_train)\n",
    "\n",
    "mean = np.mean(X_train, axis=0)\n",
    "std = np.std(X_train, axis=0)\n",
    "X_train = (X_train - mean) / std\n",
    "X_test = (X_test - mean) / std\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest, most important feature: 4, decrease in accuracy = 0.0980170220233395\n",
      "LogisticRegression, most important feature: 4, decrease in accuracy = 0.10797870784709429\n",
      "KNN-3, most important feature: 4, decrease in accuracy = 0.08117048346055955\n",
      "RandomForest, feature 0: Decrease in accuracy = 0.005361059928051359\n",
      "RandomForest, feature 1: Decrease in accuracy = -8.774238834496906e-06\n",
      "RandomForest, feature 2: Decrease in accuracy = -5.849492556442293e-06\n",
      "RandomForest, feature 3: Decrease in accuracy = 0.009186628060015911\n",
      "RandomForest, feature 4: Decrease in accuracy = 0.0980170220233395\n",
      "RandomForest, feature 5: Decrease in accuracy = 0.031400076043403446\n",
      "LogisticRegression, feature 0: Decrease in accuracy = -0.0015384165423648621\n",
      "LogisticRegression, feature 1: Decrease in accuracy = 0.0038284928782426064\n",
      "LogisticRegression, feature 2: Decrease in accuracy = 0.006127343452955403\n",
      "LogisticRegression, feature 3: Decrease in accuracy = 0.024509373811821833\n",
      "LogisticRegression, feature 4: Decrease in accuracy = 0.10797870784709429\n",
      "LogisticRegression, feature 5: Decrease in accuracy = 0.013012196191980352\n",
      "KNN-3, feature 0: Decrease in accuracy = -0.001523792810973923\n",
      "KNN-3, feature 1: Decrease in accuracy = 0.0007662835249039324\n",
      "KNN-3, feature 2: Decrease in accuracy = -0.0038138691468518893\n",
      "KNN-3, feature 3: Decrease in accuracy = 0.009198327045128685\n",
      "KNN-3, feature 4: Decrease in accuracy = 0.08117048346055955\n",
      "KNN-3, feature 5: Decrease in accuracy = 0.03371062560322868\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "classifiers = {\n",
    "    'RandomForest': RandomForestClassifier(n_estimators=100),\n",
    "    'LogisticRegression': LogisticRegression(max_iter=1000),\n",
    "    'KNN-3': KNeighborsClassifier(n_neighbors=3),\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "# For each classifier\n",
    "for classifier_name, clf in classifiers.items():\n",
    "    \n",
    "    baseline_scores = cross_val_score(clf, X_train, target_train, cv=5)\n",
    "    baseline_accuracy = np.mean(baseline_scores)\n",
    "    most_important_feature = None\n",
    "    max_decrease = 0\n",
    "    for i in range(X_train.shape[1]):\n",
    "        \n",
    "        X_train_removed = X_train.copy()\n",
    "        \n",
    "        X_train_removed = np.delete(X_train_removed, i, axis=1)\n",
    "        \n",
    "        scores_removed = cross_val_score(clf, X_train_removed, target_train, cv=5)\n",
    "        accuracy_removed = np.mean(scores_removed)\n",
    "        decrease = baseline_accuracy - accuracy_removed\n",
    "\n",
    "        # Update the most important feature and its decrease in accuracy\n",
    "        if decrease > max_decrease:\n",
    "            most_important_feature = i\n",
    "            max_decrease = decrease\n",
    "\n",
    "        results[(classifier_name, i)] = decrease\n",
    "\n",
    "    # Print the most important feature for this classifier\n",
    "    print(f'{classifier_name}, most important feature: {most_important_feature}, decrease in accuracy = {max_decrease}')\n",
    "\n",
    "# Print the results\n",
    "for (classifier_name, i), decrease in results.items():\n",
    "    print(f'{classifier_name}, feature {i}: Decrease in accuracy = {decrease}')\n",
    "#         results[(classifier_name, i)] = baseline_accuracy - accuracy_removed\n",
    "\n",
    "# # Print the results\n",
    "# for (classifier_name, i), decrease in results.items():\n",
    "#     print(f'{classifier_name}, feature {i}: Decrease in accuracy = {decrease}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature 0: Rank = 1\n",
      "Feature 1: Rank = 2\n",
      "Feature 2: Rank = 1\n",
      "Feature 3: Rank = 1\n",
      "Feature 4: Rank = 1\n",
      "Feature 5: Rank = 1\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "estimator = LogisticRegression(max_iter=1000)\n",
    "\n",
    "selector = RFE(estimator, n_features_to_select=5, step=1)\n",
    "\n",
    "selector = selector.fit(X_train, target_train)\n",
    "\n",
    "\n",
    "ranking = selector.ranking_\n",
    "\n",
    "for i, rank in enumerate(ranking):\n",
    "    print(f\"Feature {i}: Rank = {rank}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
